{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxel morph imports\n",
    "import tensorflow as tf\n",
    "import voxelmorph as vxm\n",
    "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import utilitary as util\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import neurite as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(\"epfl3.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(336699)\n",
    "\n",
    "nb_entries = len(hf.keys())\n",
    "list_keys = list(hf.keys())\n",
    "keys_random = np.random.permutation(list_keys)\n",
    "\n",
    "keys_train = keys_random[:int(nb_entries*0.8)]\n",
    "keys_test  = keys_random[int(nb_entries*0.8):]\n",
    "\n",
    "#x,y,z = hf.get(\"0\")[\"frame\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys in test with labels mask\n",
    "mask_tests = []\n",
    "for i in keys_test:\n",
    "    if len(hf.get(i)) > 1:\n",
    "        mask_tests.append(i)\n",
    "        \n",
    "# keys in test with labels mask\n",
    "mask_trains = []\n",
    "for i in keys_train:\n",
    "    if len(hf.get(i)) > 1:\n",
    "        mask_trains.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/toinou/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "vol_shape = (112, 112, 32)\n",
    "nb_features = [\n",
    "    [16, 32, 32, 32],\n",
    "    [32, 32, 32, 32, 32, 16, 16]\n",
    "]\n",
    "\n",
    "label_vals = np.array([1,2,3,4,5,6,7])\n",
    "\n",
    "vxm_model = vxm.networks.VxmDenseSemiSupervisedSeg(\n",
    "                                        inshape=vol_shape,\n",
    "                                        nb_labels=len(label_vals),\n",
    "                                        nb_unet_features=nb_features,\n",
    "                                        int_steps=0);\n",
    "key_fixed = 904\n",
    "\n",
    "\n",
    "fixed_vol = np.array(hf.get(str(key_fixed))[\"frame\"][0][:,:,:])/255\n",
    "fixed_seg = np.array(hf.get(str(key_fixed))[\"mask\"])\n",
    "\n",
    "## MSE\n",
    "#vxm_model.load_weights(\"semisup5e-5_all_labels5e-05.keras\")\n",
    "#vxm_model.load_weights(\"semisup5e-2_all_labels5e-02.keras\")\n",
    "#vxm_model.load_weights(\"semisup_01_all_labels0.1.keras\")\n",
    "\n",
    "##NCC\n",
    "vxm_model.load_weights(\"semisup_ncc_all_labels_32epoch0.9.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### PREDICTION ON UNSEEN DATA\n",
    "\n",
    "#val -> test npz\n",
    "vols_names = ['vol'+str(i)+'.npz' for i in keys_test]\n",
    "\n",
    "predict_generator = vxm.generators.semisupervised(\n",
    "                        vol_names=vols_names,\n",
    "                        labels=label_vals)\n",
    "\n",
    "val_input = [next(predict_generator) for i in range(len(mask_tests))]\n",
    "\n",
    "# predict the transformation\n",
    "val_pred = []\n",
    "for i in range(len(mask_tests)):\n",
    "    val_pred.append(vxm_model.predict(val_input[i]))\n",
    "    \n",
    "#warp_generator = util.vxm_data_generator(slices_train_3d_mask,\n",
    "                                         # vol_fixed=fixed_vol,\n",
    "                                          #batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREDICTION ON TRAINING DATA\n",
    "\n",
    "#vol -> training npz\n",
    "vols_names_tr = ['vol'+str(i)+'.npz' for i in keys_train]\n",
    "\n",
    "predict_generator = vxm.generators.semisupervised(\n",
    "                        vol_names=vols_names_tr,\n",
    "                        labels=label_vals)\n",
    "\n",
    "\n",
    "val_input = [next(predict_generator) for i in range(len(mask_trains))]\n",
    "\n",
    "# predict the transformation\n",
    "val_pred = []\n",
    "for i in range(len(mask_trains)):\n",
    "    val_pred.append(vxm_model.predict(val_input[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_model = vxm.networks.Transform(vol_shape, interp_method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before warping (rough alignment)\n",
      "after warping\n"
     ]
    }
   ],
   "source": [
    "#checking that it's the right prediction vector\n",
    "assert (len(mask_tests) == len(val_pred))\n",
    "\n",
    "#load the test set + normalization\n",
    "#slices_test_3d_frame = np.empty((len(mask_tests),112,112,32))\n",
    "slices_test_3d_mask = np.empty((len(mask_tests),112,112,32))\n",
    "for i, key in enumerate(mask_tests):\n",
    "    #slices_test_3d_frame[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "    slices_test_3d_mask[i] = np.array(hf.get(key)[\"mask\"])\n",
    "    #slices_test_3d_mask[i][np.where(slices_train_3d_mask[i] != 4)] = 0\n",
    "\n",
    "# predict the labels transformation (unseen data)\n",
    "warped_seg = [warp_model.predict([slices_test_3d_mask[i][np.newaxis,...,np.newaxis], val_pred[i][1]]) for i in range(len(mask_tests))]\n",
    "\n",
    "dice = [vxm.py.utils.dice(slices_test_3d_mask[i], fixed_seg, label_vals) for i in range(len(mask_tests))]\n",
    "#mean_dice, std_dice = avg_dice_score(slices_test_3d_mask, fixed_seg)\n",
    "print(\"before warping (rough alignment)\")\n",
    "#print(dice.mean())\n",
    "#print(dice.std())\n",
    "warped_seg = np.array(warped_seg)\n",
    "\n",
    "dice_warp = [vxm.py.utils.dice(warped_seg.squeeze()[i], fixed_seg, label_vals) for i in range(len(mask_tests))]\n",
    "#mean_dice, std_dice = avg_dice_score(warped_seg.squeeze(), fixed_seg)\n",
    "print(\"after warping\")\n",
    "#print(dice_warp.mean())\n",
    "#print(dice_warp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = np.array(dice)\n",
    "dice_warp = np.array(dice_warp)Je sais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5274078673912717\n",
      "0.22635830307831672\n",
      "***\n",
      "0.5136759294846884\n",
      "0.196082921471492\n"
     ]
    }
   ],
   "source": [
    "i =3\n",
    "print(dice[:,i].mean())\n",
    "print(dice[:,i].std())\n",
    "print('***')\n",
    "print(dice_warp[:,i].mean())\n",
    "print(dice_warp[:,i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3177257054361897\n",
      "0.29381780684812686\n"
     ]
    }
   ],
   "source": [
    "print(dice.mean())\n",
    "print(dice.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2960589320898904\n",
      "0.28417368482555944\n"
     ]
    }
   ],
   "source": [
    "print(dice_warp.mean())\n",
    "print(dice_warp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before warping (rough alignment)\n",
      "0.6684424624287555\n",
      "0.29168842949727697\n",
      "after warping\n",
      "0.690531489514495\n",
      "0.2540972284700225\n"
     ]
    }
   ],
   "source": [
    "#checking that it's the right prediction vector\n",
    "assert (len(mask_trains) == len(val_pred))\n",
    "    \n",
    "#load the training set + normalization\n",
    "#slices_train_3d_frame = np.empty((len(mask_trains),112,112,32))\n",
    "slices_train_3d_mask = np.empty((len(mask_trains),112,112,32))\n",
    "for i, key in enumerate(mask_trains):\n",
    "    #slices_train_3d_frame[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "    slices_train_3d_mask[i] = np.array(hf.get(key)[\"mask\"])\n",
    "    #slices_train_3d_mask[i][np.where(slices_train_3d_mask[i] != 4)] = 0\n",
    "\n",
    "# predict the labels transformation (training data)\n",
    "warped_seg = [warp_model.predict([slices_train_3d_mask[i][np.newaxis,...,np.newaxis], val_pred[i][1]]) for i in range(len(mask_trains))]\n",
    "means_dice_no_warp = vxm.py.utils.dice(slices_train_3d_mask, fixed_seg, label_vals)\n",
    "#mean_dice, std_dice = avg_dice_score(slices_train_3d_mask, fixed_seg)\n",
    "print(\"before warping (rough alignment)\")\n",
    "print(means_dice_no_warp.mean())\n",
    "print(means_dice_no_warp.std())\n",
    "\n",
    "warped_seg = np.array(warped_seg)\n",
    "means_dice_warp = vxm.py.utils.dice(warped_seg.squeeze(), fixed_seg, label_vals)\n",
    "#mean_dice, std_dice = avg_dice_score(warped_seg.squeeze(), fixed_seg)\n",
    "print(\"after warping\")\n",
    "print(means_dice_warp.mean())\n",
    "print(means_dice_warp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'500'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_tests[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 1080x360 with 3 Axes>,\n",
       " array([<AxesSubplot:title={'center':'hand-made labels'}>,\n",
       "        <AxesSubplot:title={'center':'atlas labels'}>,\n",
       "        <AxesSubplot:title={'center':'atlas labels warped'}>], dtype=object))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=6\n",
    "titles = ['hand-made labels', 'atlas labels', 'atlas labels warped']\n",
    "ne.plot.slices([np.max(slices_test_3d_mask[idx],axis=2),\n",
    "                np.max(fixed_seg, axis=2),\n",
    "                np.max(warped_seg[idx].squeeze(),axis=2)],\n",
    "              titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground truth\n",
    "gt = []\n",
    "#vxm perf\n",
    "vxm = []\n",
    "for i in range(len(slices_test_3d_mask)):\n",
    "    #rough prealign\n",
    "    gt.append(np.corrcoef(slices_test_3d_mask[i].ravel(),\n",
    "                    fixed_seg.ravel())[0,1])\n",
    "    \n",
    "    \n",
    "    #after morphing\n",
    "    vxm.append(np.corrcoef(slices_test_3d_mask[i].ravel(),\n",
    "                    warped_seg[i].squeeze().ravel())[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4549534176719892"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(gt).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494964188486524"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vxm).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2591554221503907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(gt).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13404250332101378"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vxm).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt3.8",
   "language": "python",
   "name": "pyt3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
