{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joVczQLTPXMZ"
   },
   "source": [
    "# Introduction to VoxelMorph\n",
    "[Adrian Dalca](http://adalca.mit.edu) and Andrew Hoopes    \n",
    "Introductory slides for this tutorial are [here](https://github.com/learn2reg/tutorials2019/blob/master/slides/Learn2reg_tutorial_unsupervided_AdrianDalca.pdf). \n",
    "\n",
    "This is a short tutorial to get you started with [VoxelMorph](https://github.com/voxelmorph/voxelmorph): deep-learning based registration.\n",
    "\n",
    "### Outline\n",
    "- **Core concepts with MNIST**   \n",
    "We will first learn to deal with data, building a model, training, registration and generalization\n",
    "- **More realistic complexity: Brain MRI (2D slices)**  \n",
    "We will then show how these models work for 2d slices of brain scans, presenting a more complex scenario    \n",
    "- **Realistic 3D Brain MRI**  \n",
    "We will illustrate full 3D registration\n",
    "- **Advances topics**  \n",
    "Finally, we close with more advanced topics, including diffeomorphisms and fine-tuning deformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tp-Br9ntPXMc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohNC6AESPXMe"
   },
   "source": [
    "We'll start with some common imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tGSrH6W-PXMf"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# voxel morph imports\n",
    "import tensorflow as tf\n",
    "import voxelmorph as vxm\n",
    "import neurite as ne\n",
    "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
    "\n",
    "#semi-supervised learning\n",
    "from numpy import savez_compressed\n",
    "\n",
    "# dataset import\n",
    "import h5py\n",
    "\n",
    "# image manipulation\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import cv2\n",
    "\n",
    "#custom functions\n",
    "import utilitary as util\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fix seed to avoid training and testing sets mixing\n",
    "np.random.seed(336699)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zfnae-bPXOc"
   },
   "source": [
    "# Registration of Brain MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset with images stored in \"frame\"\n",
    "#for some frames, a label mask is available under \"mask\"\n",
    "hf = h5py.File(\"epfl3.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training/testing sets\n",
    "nb_entries = len(hf.keys())\n",
    "list_keys = list(hf.keys())\n",
    "keys_random = np.random.permutation(list_keys)\n",
    "\n",
    "keys_train = keys_random[:int(nb_entries*0.8)]\n",
    "keys_test  = keys_random[int(nb_entries*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set + normalization\n",
    "slices_train = np.zeros((len(keys_train),112,112,32))\n",
    "for i, key in enumerate(keys_train):\n",
    "    slices_train[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set + normalization\n",
    "slices_test = np.zeros((len(keys_test),112,112,32))\n",
    "for i, key in enumerate(keys_test):\n",
    "    slices_test[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601948069007,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "4Mz97MblPXOi",
    "outputId": "10f680a9-8aea-44a6-ad2e-c8d581e5c138"
   },
   "outputs": [],
   "source": [
    "# extract some brains\n",
    "idx = np.random.randint(0, len(slices_train), 4)\n",
    "example_digits = [f for f in slices_train[idx, ...]]\n",
    "\n",
    "#2D-rization with maximal intensity projection\n",
    "MIP_example = util.np_MIP(slices_train, idx, 2)\n",
    "plots = [MIP_example[i] for i in range (len(MIP_example))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601948069007,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "4Mz97MblPXOi",
    "outputId": "10f680a9-8aea-44a6-ad2e-c8d581e5c138",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize\n",
    "ne.plot.slices(plots, cmaps=['gray'], do_colorbars=True, grid=[1,4]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5SzyH_ZPXOv"
   },
   "source": [
    "### 2D MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNkaW3rLPXOw"
   },
   "outputs": [],
   "source": [
    "# configure unet input shape (concatenation of moving and fixed images)\n",
    "\n",
    "# configure unet features \n",
    "nb_features = [\n",
    "    [32, 32, 32, 32],         # encoder features\n",
    "    [32, 32, 32, 32, 32, 16]  # decoder features\n",
    "]\n",
    "\n",
    "# build model using VxmDense\n",
    "inshape = slices_train.shape[1:]\n",
    "vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)\n",
    "\n",
    "# voxelmorph has a variety of custom loss classes\n",
    "losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
    "\n",
    "# usually, we have to balance the two losses by a hyper-parameter\n",
    "lambda_param = 0.05\n",
    "loss_weights = [1, lambda_param]\n",
    "\n",
    "vxm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1601948075860,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "-7qZ-GGQPXO8",
    "outputId": "6577238e-1565-4364-9956-4c6f62c370e7"
   },
   "outputs": [],
   "source": [
    "# let's test it\n",
    "train_generator = util.vxm_data_generator(slices_train[30:],\n",
    "                                          idx_fixed=12,\n",
    "                                          batch_size=2)\n",
    "val = util.create_xy(slices_train[:30], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBiebhXEPXPB"
   },
   "source": [
    "Looks good, time to **train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "executionInfo": {
     "elapsed": 5647,
     "status": "error",
     "timestamp": 1601948092939,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "1PyZ-RYKPXPB",
    "outputId": "728bc135-5f31-41f2-a77d-ce5a6547a814",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = vxm_model.fit(train_generator,\n",
    "                     validation_data=val,\n",
    "                     validation_batch_size = 2,\n",
    "                     epochs=3, steps_per_epoch=1, verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "executionInfo": {
     "elapsed": 59723,
     "status": "error",
     "timestamp": 1601787242495,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "bxZ7IadCPXPL",
    "outputId": "824b6b77-6481-4a80-8adc-54f7cf9ff2f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# as before, let's visualize what happened\n",
    "util.plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvmVFKcpPXPO"
   },
   "outputs": [],
   "source": [
    "val_input, _ = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opW3JpCsPXPS"
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1601948100980,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "is72zRvfPXPW",
    "outputId": "1d037150-2dc6-4f5a-f2fb-75a794e909c2"
   },
   "outputs": [],
   "source": [
    "# visualize registration\n",
    "images = [np.squeeze(util.np_MIP(np.squeeze(img),[0],2)) for img in val_input+[val_pred[0]]] \n",
    "titles = ['moving', 'fixed', 'moved', 'flow']\n",
    "ne.plot.slices(images, titles=titles[:-1], cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1axrla6VPXPf"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSQj-OWwPXPg"
   },
   "source": [
    "Evaluating registration results is tricky. The first tendancy is to look at the images (as above), and conclude that if they match, The registration has succeeded.\n",
    "\n",
    "However, this can be achieved by an optimization that only penalizes the image matching term. For example, next we compare our model with one that was trained on maximizing MSE only (without smoothness loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSo3Ec3PPXPg"
   },
   "outputs": [],
   "source": [
    "# prediction from model with MSE + smoothness loss\n",
    "vxm_model.load_weights('weights.keras')\n",
    "our_val_pred = vxm_model.predict(val_input)\n",
    "\n",
    "# prediction from model with just MSE loss\n",
    "vxm_model.load_weights('weights.keras')\n",
    "mse_val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 1401,
     "status": "ok",
     "timestamp": 1601948149973,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "AxEXwAJrPXPi",
    "outputId": "1f573462-dd48-4766-fdb2-cd6f3c04cf9c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize MSE + smoothness model output\n",
    "images = [np.squeeze(util.np_MIP(np.squeeze(img),[0],2)) for img in [val_input[1], our_val_pred[0]]]\n",
    "titles = ['fixed', 'MSE + smoothness', 'flow']\n",
    "ne.plot.slices(images, titles=titles[:-1], cmaps=['gray'], do_colorbars=True);\n",
    "\n",
    "# visualize MSE model output\n",
    "images = [np.squeeze(util.np_MIP(np.squeeze(img),[0],2)) for img in [val_input[1], mse_val_pred[0]]]\n",
    "titles = ['fixed', 'MSE only', 'flow']\n",
    "ne.plot.slices(images, titles=titles[:-1], cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZxdnWCvPXPo"
   },
   "source": [
    "# 3D SAHAND DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03eUI2GjPXPo"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpkI4qC9PXPp"
   },
   "outputs": [],
   "source": [
    "# our data will be of shape 112 x 112 x 32\n",
    "nb_features = [\n",
    "    [16, 32, 32, 32],\n",
    "    [32, 32, 32, 32, 32, 16, 16]\n",
    "]\n",
    "\n",
    "# build model using VxmDense\n",
    "inshape = slices_train.shape[1:]\n",
    "vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weight obtained on December the 11th\n",
    "vxm_model.load_weights('wght_3d_0.0005.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR declare a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxelmorph has a variety of custom loss classes\n",
    "losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
    "\n",
    "# usually, we have to balance the two losses by a hyper-parameter\n",
    "lambda_param = 0.05\n",
    "loss_weights = [1, lambda_param]\n",
    "\n",
    "vxm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve9jX06fPXPu"
   },
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set + normalization\n",
    "slices_train_3d = np.zeros((len(keys_train),112,112,32))\n",
    "for i, key in enumerate(keys_train):\n",
    "    slices_train_3d[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set + normalization\n",
    "slices_test_3d = np.zeros((len(keys_test),112,112,32))\n",
    "for i, key in enumerate(keys_test):\n",
    "    slices_test_3d[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxVPHrtVPXPx"
   },
   "outputs": [],
   "source": [
    "# create a generator with a constant fixed volume (keys='853')\n",
    "#chose this one because middle of the movie and provided with a label mask\n",
    "train_generator = util.vxm_data_generator(slices_train_3d[31:],\n",
    "                                          vol_fixed=np.array(hf.get('853')[\"frame\"][0][:,:,:])/255,\n",
    "                                          batch_size=2)\n",
    "\n",
    "xy_val = util.create_xy_3d(slices_train_3d[:31], np.array(hf.get('853')[\"frame\"][0][:,:,:])/255)\n",
    "\n",
    "hist = vxm_model.fit(train_generator,\n",
    "                     validation_data=xy_val,\n",
    "                     epochs=3, \n",
    "                     steps_per_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_history(hist, 0.05, loss_name=['loss','val_loss'], save_name = 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIGFUGxyPXPy"
   },
   "source": [
    "Now let's register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print keys in test with labels mask\n",
    "for i in keys_test[300:]:\n",
    "    if len(hf.get(i)) > 1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple input, to show warping on the labels mask\n",
    "val_input = [\n",
    "             (np.array(hf.get('1649')[\"frame\"][0][:,:,:])/255)[np.newaxis, ..., np.newaxis],\n",
    "             (np.array(hf.get('853')[\"frame\"][0][:,:,:])/255)[np.newaxis, ..., np.newaxis]\n",
    "            ]\n",
    "\n",
    "val_input[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXHBPty3PXPz"
   },
   "outputs": [],
   "source": [
    "# predict the transformation\n",
    "val_pred = vxm_model.predict(val_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMmdTCTXPXP0"
   },
   "outputs": [],
   "source": [
    "# extract the result\n",
    "moved_pred = val_pred[0].squeeze()\n",
    "pred_warp = val_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the moving, fixed and moved-prediction\n",
    "mid_slices_moving = [np.take(val_input[0].squeeze(), vol_shape[d]//2, axis=d) for d in range(3)]\n",
    "mid_slices_moving[1] = np.rot90(mid_slices_moving[1], 1)\n",
    "mid_slices_moving[2] = np.rot90(mid_slices_moving[2], -1)\n",
    "\n",
    "mid_slices_fixed = [np.take(val_input[1].squeeze(), vol_shape[d]//2, axis=d) for d in range(3)]\n",
    "mid_slices_fixed[1] = np.rot90(mid_slices_fixed[1], 1)\n",
    "mid_slices_fixed[2] = np.rot90(mid_slices_fixed[2], -1)\n",
    "\n",
    "mid_slices_pred = [np.take(moved_pred, vol_shape[d]//2, axis=d) for d in range(3)]\n",
    "mid_slices_pred[1] = np.rot90(mid_slices_pred[1], 1)\n",
    "mid_slices_pred[2] = np.rot90(mid_slices_pred[2], -1)\n",
    "ne.plot.slices(mid_slices_moving + mid_slices_fixed + mid_slices_pred,\n",
    "               cmaps=['gray'],\n",
    "               do_colorbars=True,\n",
    "               grid=[3,3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUVJDZsyPXP6"
   },
   "outputs": [],
   "source": [
    "# declare a model of the labels warping\n",
    "warp_model = vxm.networks.Transform(vol_shape, interp_method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels corresponding to the frame declared above\n",
    "labels = [\n",
    "             (np.array(hf.get('1649')[\"mask\"])/255),\n",
    "             (np.array(hf.get('853')[\"mask\"])/255)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels transformation\n",
    "warped_seg = warp_model.predict([labels[0][np.newaxis, ..., np.newaxis], pred_warp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fixed image label mask (MIP)\n",
    "ne.plot.slices(np.max(labels[1].squeeze(), axis=2), cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prediction label mask (MIP)\n",
    "ne.plot.slices(np.max(warped_seg.squeeze(), axis=2), cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add color to the plot\n",
    "from pystrum.pytools.plot import jitter\n",
    "import matplotlib\n",
    "\n",
    "[ccmap, scrambled_cmap] = jitter(255, nargout=2)\n",
    "scrambled_cmap[0, :] = np.array([0, 0, 0, 1])\n",
    "ccmap = matplotlib.colors.ListedColormap(scrambled_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the labels moving, fixed and prediction\n",
    "mid_slices_moving = [np.take(labels[0].squeeze(), vol_shape[d]//1.8, axis=d) for d in range(3)]\n",
    "mid_slices_moving[1] = np.rot90(mid_slices_moving[1], 1)\n",
    "mid_slices_moving[2] = np.rot90(mid_slices_moving[2], -1)\n",
    "\n",
    "mid_slices_fixed = [np.take(labels[1].squeeze(), vol_shape[d]//1.8, axis=d) for d in range(3)]\n",
    "mid_slices_fixed[1] = np.rot90(mid_slices_fixed[1], 1)\n",
    "mid_slices_fixed[2] = np.rot90(mid_slices_fixed[2], -1)\n",
    "\n",
    "mid_slices_pred = [np.take(warped_seg.squeeze(), vol_shape[d]//1.8, axis=d) for d in range(3)]\n",
    "mid_slices_pred[1] = np.rot90(mid_slices_pred[1], 1)\n",
    "mid_slices_pred[2] = np.rot90(mid_slices_pred[2], -1)\n",
    "\n",
    "slices = mid_slices_moving + mid_slices_fixed + mid_slices_pred\n",
    "\n",
    "ne.plot.slices(slices, cmaps = [ccmap], grid=[3,3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YsOcys-PXQD"
   },
   "source": [
    "## Semi Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys with labels mask\n",
    "masked_train = [i for i in keys_train if (len(hf.get(i)) > 1)]\n",
    "masked_test = [i for i in keys_test if (len(hf.get(i)) > 1)]\n",
    "\n",
    "labels_train_3d_semisup = np.zeros((len(masked_train),112,112,32))\n",
    "slices_train_3d_semisup = np.zeros((len(masked_train),112,112,32))\n",
    "\n",
    "labels_test_3d_semisup = np.zeros((len(masked_test),112,112,32))\n",
    "slices_test_3d_semisup = np.zeros((len(masked_test),112,112,32))\n",
    "\n",
    "#load the training set + normalization\n",
    "for i, key in enumerate(masked_train):\n",
    "    labels_train_3d_semisup[i] = np.array(hf.get(key)[\"mask\"][0])\n",
    "    slices_train_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "\n",
    "    #load the test set + normalization\n",
    "for i, key in enumerate(masked_test):\n",
    "    labels_test_3d_semisup[i] = np.array(hf.get(key)[\"mask\"][0])\n",
    "    slices_test_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a true semi-supervised training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the index of keys with frame + labels\n",
    "masked_train = [i for i in keys_train if (len(hf.get(i)) > 1)]\n",
    "\n",
    "#preallocation\n",
    "labels_train_3d_semisup = np.zeros((len(keys_train),112,112,32))\n",
    "slices_train_3d_semisup = np.zeros((len(keys_train),112,112,32))\n",
    "\n",
    "#load the training set + normalization\n",
    "for i, key in enumerate(keys_train):\n",
    "    if i in masked_train:\n",
    "        labels_train_3d_semisup[i] = np.array(hf.get(key)[\"mask\"])\n",
    "        slices_train_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "    else:\n",
    "        labels_train_3d_semisup[i] = np.zeros((112, 112,  32))\n",
    "        slices_train_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "        \n",
    "# generate a file for each semi-supervised training entry\n",
    "for i in range(len(slices_train_3d_semisup)):\n",
    "    savez_compressed('vol'+str(i)+'.npz',\n",
    "                     vol=slices_train_3d_semisup[i],\n",
    "                     seg=labels_train_3d_semisup[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the index of keys with frame + labels\n",
    "masked_test = [i for i in keys_test if (len(hf.get(i)) > 1)]\n",
    "\n",
    "#preallocation\n",
    "labels_test_3d_semisup = np.zeros((len(keys_test),112,112,32))\n",
    "slices_test_3d_semisup = np.zeros((len(keys_test),112,112,32))\n",
    "\n",
    "#load the test set + normalization\n",
    "for i, key in enumerate(keys_test[:51]):\n",
    "    if i in masked_test:\n",
    "        labels_test_3d_semisup[i] = np.array(hf.get(key)[\"mask\"])\n",
    "        slices_test_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "    else:\n",
    "        labels_test_3d_semisup[i] = np.zeros((112, 112,  32))\n",
    "        slices_test_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "        \n",
    "# generate a file for each semi-supervised training entry\n",
    "for i in range(len(slices_test_3d_semisup)):\n",
    "    savez_compressed('val'+str(i)+'.npz',\n",
    "                     vol=slices_test_3d_semisup[i],\n",
    "                     seg=labels_test_3d_semisup[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/toinou/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "# our data will be of shape 112 x 112 x 32\n",
    "vol_shape = (112, 112, 32)\n",
    "nb_features = [\n",
    "    [16, 32, 32, 32],\n",
    "    [32, 32, 32, 32, 32, 16, 16]\n",
    "]\n",
    "\n",
    "losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
    "\n",
    "lambda_param = 0.05\n",
    "loss_weights = [1, lambda_param]\n",
    "\n",
    "# declare the model, using all 7 labels values\n",
    "vxm_model_semisup = vxm.networks.VxmDenseSemiSupervisedSeg(inshape=vol_shape,\n",
    "                                                           nb_labels=7,\n",
    "                                                           nb_unet_features=nb_features,\n",
    "                                                           int_steps=0);\n",
    "\n",
    "vxm_model_semisup.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "                          loss=losses,\n",
    "                          loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_entries\n",
    "train_vols_names = ['vol'+str(i)+'.npz' for i in keys_train]\n",
    "\n",
    "test_vols_names = ['vol'+str(i)+'.npz' for i in keys_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (112,112,32,1) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0279c31b48e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m dummy_val = (np.vstack([tmp[i][0] for i in range(8)]),\n\u001b[0m\u001b[1;32m     15\u001b[0m              \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             )\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# raise warning if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (112,112,32,1) into shape (1)"
     ]
    }
   ],
   "source": [
    "# create the generator\n",
    "label_vals = np.array([1,2,3,4,5,6,7])\n",
    "train_generator = vxm.generators.semisupervised(vol_names=train_vols_names,\n",
    "                                                atlas_file='vol904.npz',\n",
    "                                                labels=label_vals\n",
    "                                               )\n",
    "\n",
    "val_generator = vxm.generators.semisupervised(vol_names=test_vols_names,\n",
    "                                              atlas_file='vol904.npz',\n",
    "                                              labels=label_vals\n",
    "                                              )\n",
    "\n",
    "tmp = [next(val_generator) for i in range(8)]\n",
    "dummy_val = (np.vstack([tmp[i][0] for i in range(8)]),\n",
    "             np.vstack([tmp[i][1] for i in range(8)])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 9s 3s/step - loss: 4.7485e-04 - vxm_dense_transformer_loss: 4.7485e-04 - vxm_dense_flow_loss: 1.4838e-07 - val_loss: 0.0000e+00 - val_vxm_dense_transformer_loss: 0.0000e+00 - val_vxm_dense_flow_loss: 0.0000e+00\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 11s 4s/step - loss: 3.3420e-04 - vxm_dense_transformer_loss: 3.3410e-04 - vxm_dense_flow_loss: 1.9783e-06 - val_loss: 0.0000e+00 - val_vxm_dense_transformer_loss: 0.0000e+00 - val_vxm_dense_flow_loss: 0.0000e+00\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 11s 4s/step - loss: 4.6810e-04 - vxm_dense_transformer_loss: 4.6772e-04 - vxm_dense_flow_loss: 7.6507e-06 - val_loss: 0.0000e+00 - val_vxm_dense_transformer_loss: 0.0000e+00 - val_vxm_dense_flow_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "hist = vxm_model_semisup.fit(train_generator,\n",
    "                             validation_data=dummy_val,\n",
    "                             validation_batch_size=2,\n",
    "                             epochs=3,\n",
    "                             steps_per_epoch=3,\n",
    "                             verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_history(hist, 0.05, loss_name=['loss', 'val_loss'], save_name = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm_model_semisup.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pgoRqis6PXNl",
    "GvBaf6puPXNx",
    "owpa6G64PXN-",
    "qBsXU7dcPXOR",
    "0zfnae-bPXOc",
    "T5SzyH_ZPXOv",
    "1axrla6VPXPf",
    "QZxdnWCvPXPo",
    "03eUI2GjPXPo",
    "Ve9jX06fPXPu",
    "1YsOcys-PXQD"
   ],
   "name": "Copy of VoxelMorph Tutorial.ipynb",
   "provenance": [
    {
     "file_id": "1WiqyF7dCdnNBIANEY80Pxw_mVz4fyV-S",
     "timestamp": 1604941380444
    }
   ]
  },
  "kernelspec": {
   "display_name": "pyt3.8",
   "language": "python",
   "name": "pyt3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
