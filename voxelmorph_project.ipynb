{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joVczQLTPXMZ"
   },
   "source": [
    "# Introduction to VoxelMorph\n",
    "[Adrian Dalca](http://adalca.mit.edu) and Andrew Hoopes    \n",
    "Introductory slides for this tutorial are [here](https://github.com/learn2reg/tutorials2019/blob/master/slides/Learn2reg_tutorial_unsupervided_AdrianDalca.pdf). \n",
    "\n",
    "This is a short tutorial to get you started with [VoxelMorph](https://github.com/voxelmorph/voxelmorph): deep-learning based registration.\n",
    "\n",
    "### Outline\n",
    "- **Core concepts with MNIST**   \n",
    "We will first learn to deal with data, building a model, training, registration and generalization\n",
    "- **More realistic complexity: Brain MRI (2D slices)**  \n",
    "We will then show how these models work for 2d slices of brain scans, presenting a more complex scenario    \n",
    "- **Realistic 3D Brain MRI**  \n",
    "We will illustrate full 3D registration\n",
    "- **Advances topics**  \n",
    "Finally, we close with more advanced topics, including diffeomorphisms and fine-tuning deformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tp-Br9ntPXMc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohNC6AESPXMe"
   },
   "source": [
    "We'll start with some common imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGSrH6W-PXMf"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, sys\n",
    "\n",
    "# voxel morph imports\n",
    "import tensorflow as tf\n",
    "import voxelmorph as vxm\n",
    "import neurite as ne\n",
    "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
    "\n",
    "#semi-supervised learning\n",
    "from numpy import savez_compressed\n",
    "\n",
    "# dataset import\n",
    "import h5py\n",
    "\n",
    "# image manipulation\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import cv2\n",
    "\n",
    "#custom functions\n",
    "import utilitary as util\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#fix seed to avoid training and testing sets mixing\n",
    "np.random.seed(336699)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zfnae-bPXOc"
   },
   "source": [
    "# Registration of Brain MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset with images stored in \"frame\"\n",
    "#for some frames, a label mask is available under \"mask\"\n",
    "hf = h5py.File(\"epfl3.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training/testing sets\n",
    "nb_entries = len(hf.keys())\n",
    "list_keys = list(hf.keys())\n",
    "keys_random = np.random.permutation(list_keys)\n",
    "\n",
    "keys_train = keys_random[:int(nb_entries*0.8)]\n",
    "keys_test  = keys_random[int(nb_entries*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set + normalization\n",
    "slices_train = np.zeros((len(keys_train),112,112,32))\n",
    "for i, key in enumerate(keys_train):\n",
    "    slices_train[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set + normalization\n",
    "slices_test = np.zeros((len(keys_test),112,112,32))\n",
    "for i, key in enumerate(keys_test):\n",
    "    slices_test[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601948069007,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "4Mz97MblPXOi",
    "outputId": "10f680a9-8aea-44a6-ad2e-c8d581e5c138"
   },
   "outputs": [],
   "source": [
    "# extract some brains\n",
    "idx = np.random.randint(0, len(slices_train), 4)\n",
    "example_digits = [f for f in slices_train[idx, ...]]\n",
    "\n",
    "#2D-rization with maximal intensity projection\n",
    "MIP_example = util.np_MIP(slices_train, idx, 2)\n",
    "plots = [MIP_example[i] for i in range (len(MIP_example))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1601948069007,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "4Mz97MblPXOi",
    "outputId": "10f680a9-8aea-44a6-ad2e-c8d581e5c138",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize\n",
    "ne.plot.slices(plots, cmaps=['gray'], do_colorbars=True, grid=[1,4]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5SzyH_ZPXOv"
   },
   "source": [
    "### 2D MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNkaW3rLPXOw"
   },
   "outputs": [],
   "source": [
    "# configure unet input shape (concatenation of moving and fixed images)\n",
    "\n",
    "# configure unet features \n",
    "nb_features = [\n",
    "    [32, 32, 32, 32],         # encoder features\n",
    "    [32, 32, 32, 32, 32, 16]  # decoder features\n",
    "]\n",
    "\n",
    "# build model using VxmDense\n",
    "inshape = slices_train.shape[1:]\n",
    "vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)\n",
    "\n",
    "# voxelmorph has a variety of custom loss classes\n",
    "losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
    "\n",
    "# usually, we have to balance the two losses by a hyper-parameter\n",
    "lambda_param = 0.05\n",
    "loss_weights = [1, lambda_param]\n",
    "\n",
    "vxm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1601948075860,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "-7qZ-GGQPXO8",
    "outputId": "6577238e-1565-4364-9956-4c6f62c370e7"
   },
   "outputs": [],
   "source": [
    "# let's test it\n",
    "train_generator = util.vxm_data_generator(slices_train[30:],\n",
    "                                          idx_fixed=12,\n",
    "                                          batch_size=2)\n",
    "val = util.create_xy(slices_train[:30], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBiebhXEPXPB"
   },
   "source": [
    "Looks good, time to **train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "executionInfo": {
     "elapsed": 5647,
     "status": "error",
     "timestamp": 1601948092939,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "1PyZ-RYKPXPB",
    "outputId": "728bc135-5f31-41f2-a77d-ce5a6547a814",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = vxm_model.fit(train_generator,\n",
    "                     validation_data=val,\n",
    "                     validation_batch_size = 2,\n",
    "                     epochs=3, steps_per_epoch=1, verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "executionInfo": {
     "elapsed": 59723,
     "status": "error",
     "timestamp": 1601787242495,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "bxZ7IadCPXPL",
    "outputId": "824b6b77-6481-4a80-8adc-54f7cf9ff2f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# as before, let's visualize what happened\n",
    "util.plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvmVFKcpPXPO"
   },
   "outputs": [],
   "source": [
    "val_input, _ = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opW3JpCsPXPS"
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1601948100980,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "is72zRvfPXPW",
    "outputId": "1d037150-2dc6-4f5a-f2fb-75a794e909c2"
   },
   "outputs": [],
   "source": [
    "# visualize registration\n",
    "images = [np.squeeze(util.np_MIP(np.squeeze(img),[0],2)) for img in val_input+[val_pred[0]]] \n",
    "titles = ['moving', 'fixed', 'moved', 'flow']\n",
    "ne.plot.slices(images, titles=titles[:-1], cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1axrla6VPXPf"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSQj-OWwPXPg"
   },
   "source": [
    "Evaluating registration results is tricky. The first tendancy is to look at the images (as above), and conclude that if they match, The registration has succeeded.\n",
    "\n",
    "However, this can be achieved by an optimization that only penalizes the image matching term. For example, next we compare our model with one that was trained on maximizing MSE only (without smoothness loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSo3Ec3PPXPg"
   },
   "outputs": [],
   "source": [
    "# prediction from model with MSE + smoothness loss\n",
    "vxm_model.load_weights('weights.keras')\n",
    "our_val_pred = vxm_model.predict(val_input)\n",
    "\n",
    "# prediction from model with just MSE loss\n",
    "vxm_model.load_weights('weights.keras')\n",
    "mse_val_pred = vxm_model.predict(val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 1401,
     "status": "ok",
     "timestamp": 1601948149973,
     "user": {
      "displayName": "Andrew Hoopes",
      "photoUrl": "",
      "userId": "14593497792402207456"
     },
     "user_tz": 240
    },
    "id": "AxEXwAJrPXPi",
    "outputId": "1f573462-dd48-4766-fdb2-cd6f3c04cf9c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize MSE + smoothness model output\n",
    "images = [np.squeeze(util.np_MIP(np.squeeze(img),[0],2)) for img in [val_input[1], our_val_pred[0]]]\n",
    "titles = ['fixed', 'MSE + smoothness', 'flow']\n",
    "ne.plot.slices(images, titles=titles[:-1], cmaps=['gray'], do_colorbars=True);\n",
    "\n",
    "# visualize MSE model output\n",
    "images = [np.squeeze(util.np_MIP(np.squeeze(img),[0],2)) for img in [val_input[1], mse_val_pred[0]]]\n",
    "titles = ['fixed', 'MSE only', 'flow']\n",
    "ne.plot.slices(images, titles=titles[:-1], cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZxdnWCvPXPo"
   },
   "source": [
    "# 3D SAHAND DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03eUI2GjPXPo"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpkI4qC9PXPp"
   },
   "outputs": [],
   "source": [
    "# our data will be of shape 112 x 112 x 32\n",
    "nb_features = [\n",
    "    [16, 32, 32, 32],\n",
    "    [32, 32, 32, 32, 32, 16, 16]\n",
    "]\n",
    "\n",
    "# build model using VxmDense\n",
    "inshape = slices_train.shape[1:]\n",
    "vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weight obtained on December the 11th\n",
    "vxm_model.load_weights('wght_3d_0.0005.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR declare a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxelmorph has a variety of custom loss classes\n",
    "losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
    "\n",
    "# usually, we have to balance the two losses by a hyper-parameter\n",
    "lambda_param = 0.05\n",
    "loss_weights = [1, lambda_param]\n",
    "\n",
    "vxm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4), loss=losses, loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve9jX06fPXPu"
   },
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set + normalization\n",
    "slices_train_3d = np.zeros((len(keys_train),112,112,32))\n",
    "for i, key in enumerate(keys_train):\n",
    "    slices_train_3d[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the training set + normalization\n",
    "slices_test_3d = np.zeros((len(keys_test),112,112,32))\n",
    "for i, key in enumerate(keys_test):\n",
    "    slices_test_3d[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxVPHrtVPXPx"
   },
   "outputs": [],
   "source": [
    "# create a generator with a constant fixed volume (keys='853')\n",
    "#chose this one because middle of the movie and provided with a label mask\n",
    "train_generator = util.vxm_data_generator(slices_train_3d[31:],\n",
    "                                          vol_fixed=np.array(hf.get('853')[\"frame\"][0][:,:,:])/255,\n",
    "                                          batch_size=2)\n",
    "\n",
    "xy_val = util.create_xy_3d(slices_train_3d[:31], np.array(hf.get('853')[\"frame\"][0][:,:,:])/255)\n",
    "\n",
    "hist = vxm_model.fit(train_generator,\n",
    "                     validation_data=xy_val,\n",
    "                     epochs=3, \n",
    "                     steps_per_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_history(hist, 0.05, loss_name=['loss','val_loss'], save_name = 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIGFUGxyPXPy"
   },
   "source": [
    "Now let's register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print keys in test with labels mask\n",
    "for i in keys_test[300:]:\n",
    "    if len(hf.get(i)) > 1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple input, to show warping on the labels mask\n",
    "val_input = [\n",
    "             (np.array(hf.get('1649')[\"frame\"][0][:,:,:])/255)[np.newaxis, ..., np.newaxis],\n",
    "             (np.array(hf.get('853')[\"frame\"][0][:,:,:])/255)[np.newaxis, ..., np.newaxis]\n",
    "            ]\n",
    "\n",
    "val_input[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXHBPty3PXPz"
   },
   "outputs": [],
   "source": [
    "# predict the transformation\n",
    "val_pred = vxm_model.predict(val_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMmdTCTXPXP0"
   },
   "outputs": [],
   "source": [
    "# extract the result\n",
    "moved_pred = val_pred[0].squeeze()\n",
    "pred_warp = val_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the moving, fixed and moved-prediction\n",
    "mid_slices_moving = [np.take(val_input[0].squeeze(), vol_shape[d]//2, axis=d) for d in range(3)]\n",
    "mid_slices_moving[1] = np.rot90(mid_slices_moving[1], 1)\n",
    "mid_slices_moving[2] = np.rot90(mid_slices_moving[2], -1)\n",
    "\n",
    "mid_slices_fixed = [np.take(val_input[1].squeeze(), vol_shape[d]//2, axis=d) for d in range(3)]\n",
    "mid_slices_fixed[1] = np.rot90(mid_slices_fixed[1], 1)\n",
    "mid_slices_fixed[2] = np.rot90(mid_slices_fixed[2], -1)\n",
    "\n",
    "mid_slices_pred = [np.take(moved_pred, vol_shape[d]//2, axis=d) for d in range(3)]\n",
    "mid_slices_pred[1] = np.rot90(mid_slices_pred[1], 1)\n",
    "mid_slices_pred[2] = np.rot90(mid_slices_pred[2], -1)\n",
    "ne.plot.slices(mid_slices_moving + mid_slices_fixed + mid_slices_pred,\n",
    "               cmaps=['gray'],\n",
    "               do_colorbars=True,\n",
    "               grid=[3,3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUVJDZsyPXP6"
   },
   "outputs": [],
   "source": [
    "# declare a model of the labels warping\n",
    "warp_model = vxm.networks.Transform(vol_shape, interp_method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels corresponding to the frame declared above\n",
    "labels = [\n",
    "             (np.array(hf.get('1649')[\"mask\"])/255),\n",
    "             (np.array(hf.get('853')[\"mask\"])/255)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels transformation\n",
    "warped_seg = warp_model.predict([labels[0][np.newaxis, ..., np.newaxis], pred_warp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the fixed image label mask (MIP)\n",
    "ne.plot.slices(np.max(labels[1].squeeze(), axis=2), cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prediction label mask (MIP)\n",
    "ne.plot.slices(np.max(warped_seg.squeeze(), axis=2), cmaps=['gray'], do_colorbars=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add color to the plot\n",
    "from pystrum.pytools.plot import jitter\n",
    "import matplotlib\n",
    "\n",
    "[ccmap, scrambled_cmap] = jitter(255, nargout=2)\n",
    "scrambled_cmap[0, :] = np.array([0, 0, 0, 1])\n",
    "ccmap = matplotlib.colors.ListedColormap(scrambled_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the labels moving, fixed and prediction\n",
    "mid_slices_moving = [np.take(labels[0].squeeze(), vol_shape[d]//1.8, axis=d) for d in range(3)]\n",
    "mid_slices_moving[1] = np.rot90(mid_slices_moving[1], 1)\n",
    "mid_slices_moving[2] = np.rot90(mid_slices_moving[2], -1)\n",
    "\n",
    "mid_slices_fixed = [np.take(labels[1].squeeze(), vol_shape[d]//1.8, axis=d) for d in range(3)]\n",
    "mid_slices_fixed[1] = np.rot90(mid_slices_fixed[1], 1)\n",
    "mid_slices_fixed[2] = np.rot90(mid_slices_fixed[2], -1)\n",
    "\n",
    "mid_slices_pred = [np.take(warped_seg.squeeze(), vol_shape[d]//1.8, axis=d) for d in range(3)]\n",
    "mid_slices_pred[1] = np.rot90(mid_slices_pred[1], 1)\n",
    "mid_slices_pred[2] = np.rot90(mid_slices_pred[2], -1)\n",
    "\n",
    "slices = mid_slices_moving + mid_slices_fixed + mid_slices_pred\n",
    "\n",
    "ne.plot.slices(slices, cmaps = [ccmap], grid=[3,3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YsOcys-PXQD"
   },
   "source": [
    "## Semi Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys with labels mask\n",
    "masked_train = [i for i in keys_train if (len(hf.get(i)) > 1)]\n",
    "masked_test = [i for i in keys_test if (len(hf.get(i)) > 1)]\n",
    "\n",
    "labels_train_3d_semisup = np.zeros((len(masked_train),112,112,32))\n",
    "slices_train_3d_semisup = np.zeros((len(masked_train),112,112,32))\n",
    "\n",
    "labels_test_3d_semisup = np.zeros((len(masked_test),112,112,32))\n",
    "slices_test_3d_semisup = np.zeros((len(masked_test),112,112,32))\n",
    "\n",
    "#load the training set + normalization\n",
    "for i, key in enumerate(masked_train):\n",
    "    labels_train_3d_semisup[i] = np.array(hf.get(key)[\"mask\"][0])\n",
    "    slices_train_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "\n",
    "    #load the test set + normalization\n",
    "for i, key in enumerate(masked_test):\n",
    "    labels_test_3d_semisup[i] = np.array(hf.get(key)[\"mask\"][0])\n",
    "    slices_test_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a true semi-supervised training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the index of keys with frame + labels\n",
    "masked_train = [i for i in keys_train if (len(hf.get(i)) > 1)]\n",
    "\n",
    "#preallocation\n",
    "labels_train_3d_semisup = np.zeros((len(keys_train),112,112,32))\n",
    "slices_train_3d_semisup = np.zeros((len(keys_train),112,112,32))\n",
    "\n",
    "#load the training set + normalization\n",
    "for i, key in enumerate(keys_train):\n",
    "    if i in masked_train:\n",
    "        labels_train_3d_semisup[i] = np.array(hf.get(key)[\"mask\"])\n",
    "        slices_train_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "    else:\n",
    "        labels_train_3d_semisup[i] = np.zeros((112, 112,  32))\n",
    "        slices_train_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "        \n",
    "# generate a file for each semi-supervised training entry\n",
    "for i in range(len(slices_train_3d_semisup)):\n",
    "    savez_compressed('vol'+str(i)+'.npz',\n",
    "                     vol=slices_train_3d_semisup[i],\n",
    "                     seg=labels_train_3d_semisup[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the index of keys with frame + labels\n",
    "masked_test = [i for i in keys_test if (len(hf.get(i)) > 1)]\n",
    "\n",
    "#preallocation\n",
    "labels_test_3d_semisup = np.zeros((len(keys_test),112,112,32))\n",
    "slices_test_3d_semisup = np.zeros((len(keys_test),112,112,32))\n",
    "\n",
    "#load the test set + normalization\n",
    "for i, key in enumerate(keys_test[:51]):\n",
    "    if i in masked_test:\n",
    "        labels_test_3d_semisup[i] = np.array(hf.get(key)[\"mask\"])\n",
    "        slices_test_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "    else:\n",
    "        labels_test_3d_semisup[i] = np.zeros((112, 112,  32))\n",
    "        slices_test_3d_semisup[i] = np.array(hf.get(key)[\"frame\"][0][:,:,:])/255\n",
    "        \n",
    "# generate a file for each semi-supervised training entry\n",
    "for i in range(len(slices_test_3d_semisup)):\n",
    "    savez_compressed('val'+str(i)+'.npz',\n",
    "                     vol=slices_test_3d_semisup[i],\n",
    "                     seg=labels_test_3d_semisup[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data will be of shape 112 x 112 x 32\n",
    "vol_shape = (112, 112, 32)\n",
    "nb_features = [\n",
    "    [16, 32, 32, 32],\n",
    "    [32, 32, 32, 32, 32, 16, 16]\n",
    "]\n",
    "\n",
    "losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
    "\n",
    "lambda_param = 0.05\n",
    "loss_weights = [1, lambda_param]\n",
    "\n",
    "# declare the model, using all 7 labels values\n",
    "vxm_model_semisup = vxm.networks.VxmDenseSemiSupervisedSeg(inshape=vol_shape,\n",
    "                                                           nb_labels=7,\n",
    "                                                           nb_unet_features=nb_features,\n",
    "                                                           int_steps=0);\n",
    "\n",
    "vxm_model_semisup.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "                          loss=losses,\n",
    "                          loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_entries\n",
    "train_vols_names = ['vol'+str(i)+'.npz' for i in keys_train]\n",
    "\n",
    "test_vols_names = ['vol'+str(i)+'.npz' for i in keys_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the generator\n",
    "label_vals = np.array([1,2,3,4,5,6,7])\n",
    "train_generator = vxm.generators.semisupervised(vol_names=train_vols_names,\n",
    "                                                atlas_file='vol904.npz',\n",
    "                                                labels=label_vals\n",
    "                                               )\n",
    "\n",
    "val_generator = vxm.generators.semisupervised(vol_names=test_vols_names,\n",
    "                                              atlas_file='vol904.npz',\n",
    "                                              labels=label_vals\n",
    "                                              )\n",
    "\n",
    "tmp = [next(val_generator) for i in range(8)]\n",
    "x = [\n",
    "    [tmp[i][0][0] for i in range(8)],\n",
    "    [tmp[i][0][1] for i in range(8)],\n",
    "    [tmp[i][0][2] for i in range(8)]\n",
    "    ]\n",
    "y = [\n",
    "    [tmp[i][1][0] for i in range(8)],\n",
    "    [tmp[i][1][1] for i in range(8)],\n",
    "    [tmp[i][1][2] for i in range(8)]\n",
    "]\n",
    "dummy_val = (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Input to reshape is a tensor with 401408 values, but the requested shape requires a multiple of 524288\n\t [[node vxm_dense_semi_supervised_seg_1/vxm_dense_transformer/Reshape (defined at /home/toinou/Documents/master/ma1/ml/ml_proj2/voxelmorph/tf/layers.py:156) ]] [Op:__inference_train_function_13666]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node vxm_dense_semi_supervised_seg_1/vxm_dense_transformer/Reshape:\n IteratorGetNext (defined at <ipython-input-9-0b543dd1156f>:2)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7cff2989b4c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m hist = vxm_model_semisup.fit(train_generator,\n\u001b[0m\u001b[1;32m      3\u001b[0m                              \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venvs/pyt3.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 401408 values, but the requested shape requires a multiple of 524288\n\t [[node vxm_dense_semi_supervised_seg_1/vxm_dense_transformer/Reshape (defined at /home/toinou/Documents/master/ma1/ml/ml_proj2/voxelmorph/tf/layers.py:156) ]] [Op:__inference_train_function_13666]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node vxm_dense_semi_supervised_seg_1/vxm_dense_transformer/Reshape:\n IteratorGetNext (defined at <ipython-input-9-0b543dd1156f>:2)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "hist = vxm_model_semisup.fit(train_generator,\n",
    "                             validation_data=dummy_val,\n",
    "                             validation_batch_size=4,\n",
    "                             epochs=3,\n",
    "                             steps_per_epoch=3,\n",
    "                             verbose=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.plot_history(hist, 0.05, loss_name=['loss', 'val_loss'], save_name = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm.generators.semisupervised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pgoRqis6PXNl",
    "GvBaf6puPXNx",
    "owpa6G64PXN-",
    "qBsXU7dcPXOR",
    "0zfnae-bPXOc",
    "T5SzyH_ZPXOv",
    "1axrla6VPXPf",
    "QZxdnWCvPXPo",
    "03eUI2GjPXPo",
    "Ve9jX06fPXPu",
    "1YsOcys-PXQD"
   ],
   "name": "Copy of VoxelMorph Tutorial.ipynb",
   "provenance": [
    {
     "file_id": "1WiqyF7dCdnNBIANEY80Pxw_mVz4fyV-S",
     "timestamp": 1604941380444
    }
   ]
  },
  "kernelspec": {
   "display_name": "pyt3.8",
   "language": "python",
   "name": "pyt3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
